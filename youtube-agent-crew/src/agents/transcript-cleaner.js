/**
 * AGENT: Transcript Cleaner
 * 
 * Reads raw YouTube auto-caption transcripts (Vietnamese) and:
 * 1. Fixes spelling/diacritical errors from auto-captions
 * 2. Removes sponsor/ad segments embedded in content
 * 3. Fixes proper nouns (people, brands, technical terms)
 * 4. Adds paragraph breaks for readability
 * 5. Preserves the original meaning and structure
 * 
 * Input: Raw transcript text (from .md files)
 * Output: Clean, corrected Vietnamese transcript
 * 
 * Model: GPT-4o-mini (cheap, fast, good enough for text correction)
 * Strategy: Process in chunks of ~4000 chars to stay within context limits
 *           and maintain quality. Overlap 200 chars between chunks for continuity.
 */
import { BaseAgent } from '../core/agent.js';
import { chat, estimateCost } from '../core/llm.js';
import { readFile, writeFile, mkdir } from 'fs/promises';
import { join, dirname } from 'path';
import { fileURLToPath } from 'url';
import chalk from 'chalk';

const __dirname = dirname(fileURLToPath(import.meta.url));
const TRANSCRIPTS_DIR = join(__dirname, '..', 'knowledge', 'transcripts');

const SYSTEM_PROMPT = `Báº¡n lÃ  chuyÃªn gia hiá»‡u Ä‘Ã­nh vÄƒn báº£n tiáº¿ng Viá»‡t. Nhiá»‡m vá»¥: sá»­a lá»—i transcript tá»« YouTube auto-captions.

NHIá»†M Vá»¤ CHÃNH:
1. Sá»¬A Lá»–I CHÃNH Táº¢ & Dáº¤U: YouTube auto-captions thÆ°á»ng nuá»‘t dáº¥u, sai dáº¥u, ghÃ©p sai Ã¢m tiáº¿t.
   VÃ­ dá»¥ phá»• biáº¿n: "Ä‘oÃ n báº£y" â†’ "Ä‘Ã²n báº©y", "lÃ¢u nháº­n" â†’ "lá»£i nhuáº­n", "tu" â†’ "tá»± do", "sÃ³t" â†’ "short",
   "tiy" â†’ "tá»·", "lÃ¡c" â†’ "láº¡c", "báº£" â†’ "báº£n", "Ä‘á»‰" â†’ "Ä‘á»‰nh", "máº£i mÃª" Ä‘Ãºng rá»“i, giá»¯ nguyÃªn.

2. Sá»¬A THUáº¬T NGá»® CHUYÃŠN NGÃ€NH:
   - Crypto/TÃ i chÃ­nh: "Chen Linking" â†’ "Chainlink", "RVK" â†’ "RWA", "Alcoin" â†’ "Altcoin", 
     "Makinbeker" â†’ "Market Maker", "Alflow" â†’ "Outflow", "DXI" â†’ "DXY", "mimcoin" â†’ "memecoin",
     "marketer" â†’ "Market Maker", "sport" â†’ "spot", "Fidelity" giá»¯ nguyÃªn
   - TÃ¢m lÃ½: "dopamin" â†’ "dopamine", "oxyin" â†’ "oxy-tocin" hoáº·c giá»¯ náº¿u ngá»¯ cáº£nh Ä‘Ãºng
   - TÃªn riÃªng: Giá»¯ nguyÃªn tÃªn sÃ¡ch, tÃ¡c giáº£, tá»• chá»©c náº¿u nháº­n ra Ä‘Æ°á»£c

3. XÃ“A ÄOáº N QUáº¢NG CÃO/SPONSOR: CÃ¡c transcript thÆ°á»ng xen Ä‘oáº¡n quáº£ng cÃ¡o giá»¯a ná»™i dung.
   Dáº¤U HIá»†U NHáº¬N BIáº¾T:
   - "Cháº­m má»™t nhá»‹p thÃ´i, báº¡n sáº½ thÃ nh ngÆ°á»i tá»‘i cá»• ngay" â†’ thÆ°á»ng lÃ  intro sponsor
   - Gemini Pro, ChatGPT, Netflix, YouTube Premium, tÃ i khoáº£n... â†’ sponsor segment
   - "SÆ¡n Háº£i Nguyá»…n", "Ä‘áº§u tÆ° thÃ´ng minh bá»©t phÃ¡ giá»›i háº¡n" â†’ sponsor
   - "Báº£o hÃ nh thÃ©p", "lá»—i lÃ  hoÃ n tiá»n", "cÃ i Ä‘áº·t táº­n tÃ¬nh" â†’ sponsor
   - "há»— trá»£ 24/7", "link á»Ÿ mÃ´ táº£", "giáº£m giÃ¡ X%" â†’ sponsor
   - Báº¥t ká»³ Ä‘oáº¡n nÃ o quáº£ng bÃ¡ dá»‹ch vá»¥/sáº£n pháº©m khÃ´ng liÃªn quan Ä‘áº¿n ná»™i dung chÃ­nh
   â†’ XÃ“A TOÃ€N Bá»˜ Ä‘oáº¡n sponsor, KHÃ”NG giá»¯ láº¡i báº¥t ká»³ pháº§n nÃ o.

4. NGáº®T ÄOáº N: ThÃªm xuá»‘ng dÃ²ng (\\n\\n) khi chuyá»ƒn Ã½, má»—i Ä‘oáº¡n 3-5 cÃ¢u. Táº¡o Ä‘oáº¡n vÄƒn rÃµ rÃ ng.

5. Sá»¬A INTRO/OUTRO Cá»¦A KÃŠNH: 
   - "ChÃ o má»«ng Ä‘áº¿n vá»›i Self" â†’ "ChÃ o má»«ng Ä‘áº¿n vá»›i The Hidden Self"
   - "ChÃ o má»«ng Ä‘áº¿n vá»›i The Hid" â†’ "ChÃ o má»«ng Ä‘áº¿n vá»›i The Hidden Self"
   - Giá»¯ nguyÃªn cÃ¡c cÃ¢u signature cá»§a kÃªnh náº¿u nháº­n ra Ä‘Æ°á»£c.

QUY Táº®C TUYá»†T Äá»I:
- KHÃ”NG thÃªm thÃ´ng tin má»›i, KHÃ”NG sÃ¡ng tÃ¡c ná»™i dung
- KHÃ”NG thay Ä‘á»•i Ã½ nghÄ©a, KHÃ”NG tÃ³m táº¯t
- GIá»® NGUYÃŠN giá»ng vÄƒn, phong cÃ¡ch, cáº£m xÃºc cá»§a ngÆ°á»i nÃ³i
- CHá»ˆ output vÄƒn báº£n Ä‘Ã£ sá»­a, KHÃ”NG thÃªm ghi chÃº hay giáº£i thÃ­ch
- Náº¿u khÃ´ng cháº¯c má»™t tá»« sai hay Ä‘Ãºng â†’ GIá»® NGUYÃŠN`;

const CHUNK_SIZE = 6000;    // chars per chunk (larger = fewer API calls, better context)
const CHUNK_OVERLAP = 200;  // overlap for continuity

// Known sponsor/ad patterns to strip in post-processing
const SPONSOR_PATTERNS = [
  // "SÆ¡n Háº£i Nguyá»…n" sponsor block
  /Cháº­m má»™t nhá»‹p thÃ´i[\s\S]*?bá»©t phÃ¡ giá»›i háº¡n\.?/gi,
  // Gemini Pro ad
  /Gemini Pro khÃ´ng chá»‰ tráº£ lá»i[\s\S]*?(?:bá»©t phÃ¡ giá»›i háº¡n|láº­p tá»©c|chu Ä‘Ã¡o)\.?/gi,
  // Generic sponsor with known markers
  /(?:Äá»«ng bá» lá»¡ cÃ´ng nghá»‡ nÃ y|hÃ£y Ä‘áº¿n SÆ¡n Háº£i Nguyá»…n)[\s\S]*?(?:bá»©t phÃ¡ giá»›i háº¡n|láº­p tá»©c|chu Ä‘Ã¡o)\.?/gi,
  // "link á»Ÿ mÃ´ táº£" type CTAs for sponsors
  /(?:Link (?:á»Ÿ |trong )?mÃ´ táº£|Link bÃªn dÆ°á»›i|MÃ£ giáº£m giÃ¡)[\s\S]{0,300}?(?:giáº£m giÃ¡|Æ°u Ä‘Ã£i|click|nháº¥n vÃ o)\.?/gi,
  // Standalone "SÆ¡n Háº£i Nguyá»…n Ä‘áº§u tÆ° thÃ´ng minh" tagline
  /SÆ¡n Háº£i Nguyá»…n[^.]*?(?:thÃ´ng minh|giá»›i háº¡n)\.?/gi,
  // Any "báº£o hÃ nh thÃ©p, lá»—i lÃ  hoÃ n tiá»n" block
  /[Bb]áº£o hÃ nh thÃ©p[\s\S]*?(?:láº­p tá»©c|chu Ä‘Ã¡o|táº­n tÃ¬nh)\.?/gi,
  // Netflix/YouTube Premium/ChatGPT account selling
  /[Ss]áºµn kho tÃ i khoáº£n[\s\S]*?(?:ChatGPT|CHGBT|Premium)\.?/gi,
];

export class TranscriptCleanerAgent extends BaseAgent {
  constructor() {
    super({
      id: 'transcript-cleaner',
      name: 'ğŸ§¹ Transcript Cleaner',
      role: 'Vietnamese Transcript Editor & Proofreader',
      model: process.env.TRANSCRIPT_CLEANER_MODEL || 'gpt-4o-mini',
      systemPrompt: SYSTEM_PROMPT,
      temperature: 0.3, // Low temperature for accurate corrections
      maxTokens: 8192,
    });
  }

  /**
   * Clean a single transcript
   * @param {string} text - Raw transcript text (without frontmatter)
   * @param {string} title - Video title (for context)
   * @param {string} category - Video category (for context)
   * @returns {Promise<{cleaned: string, stats: object}>}
   */
  async cleanTranscript(text, title = '', category = '') {
    if (!text || text.length < 50) {
      return { cleaned: text, stats: { chunks: 0, unchanged: true } };
    }

    // Split into chunks with overlap
    const chunks = this._splitIntoChunks(text);
    this.log(`Processing ${chunks.length} chunks (${text.length} chars) â€” "${title.substring(0, 50)}..."`);

    const cleanedChunks = [];
    let totalInputTokens = 0;
    let totalOutputTokens = 0;

    for (let i = 0; i < chunks.length; i++) {
      const chunk = chunks[i];
      const contextHint = i === 0
        ? `ÄÃ¢y lÃ  PHáº¦N Äáº¦U cá»§a transcript video "${title}" (chuyÃªn má»¥c: ${category}).`
        : `ÄÃ¢y lÃ  PHáº¦N ${i + 1}/${chunks.length} (tiáº¿p ná»‘i tá»« Ä‘oáº¡n trÆ°á»›c).`;

      const userMessage = `${contextHint}\n\nHÃ£y sá»­a lá»—i vÃ  lÃ m sáº¡ch Ä‘oáº¡n transcript sau:\n\n---\n${chunk}\n---`;

      try {
        const result = await chat({
          model: this.model,
          systemPrompt: this.systemPrompt,
          userMessage,
          temperature: this.temperature,
          maxTokens: this.maxTokens,
        });

        cleanedChunks.push(result.content.trim());
        totalInputTokens += result.tokens.input;
        totalOutputTokens += result.tokens.output;

      } catch (error) {
        this.log(`Chunk ${i + 1} failed: ${error.message}`, 'warn');
        // Fallback: keep original chunk
        cleanedChunks.push(chunk);
      }
    }

    // Merge chunks (remove overlap duplicates)
    let cleaned = this._mergeChunks(cleanedChunks);

    // Post-processing: strip any remaining sponsor segments the LLM missed
    cleaned = this._removeSponsorSegments(cleaned);

    // Clean up extra whitespace
    cleaned = cleaned.replace(/\n{3,}/g, '\n\n').trim();

    // Track costs
    this.totalTokens.input += totalInputTokens;
    this.totalTokens.output += totalOutputTokens;
    this.totalCost += estimateCost(this.model, totalInputTokens, totalOutputTokens);
    this.executionCount++;

    const stats = {
      chunks: chunks.length,
      originalChars: text.length,
      cleanedChars: cleaned.length,
      reduction: ((1 - cleaned.length / text.length) * 100).toFixed(1) + '%',
      inputTokens: totalInputTokens,
      outputTokens: totalOutputTokens,
      cost: estimateCost(this.model, totalInputTokens, totalOutputTokens),
    };

    return { cleaned, stats };
  }

  /**
   * Process a single .md transcript file
   * Preserves YAML frontmatter, cleans body content
   * Saves cleaned version to transcripts-clean/{category}/{videoId}.md
   */
  async processFile(filePath, outputDir = null) {
    const content = await readFile(join(TRANSCRIPTS_DIR, filePath), 'utf-8');

    // Split frontmatter and body
    const fmMatch = content.match(/^(---[\s\S]*?---)\s*\n([\s\S]*)$/);
    if (!fmMatch) {
      this.log(`No frontmatter found: ${filePath}`, 'warn');
      return null;
    }

    const frontmatter = fmMatch[1];
    const body = fmMatch[2].trim();

    // Extract metadata from frontmatter
    const titleMatch = frontmatter.match(/title:\s*"(.+?)"/);
    const categoryMatch = frontmatter.match(/category:\s*"(.+?)"/);
    const title = titleMatch?.[1] || '';
    const category = categoryMatch?.[1] || '';

    // Extract just the transcript text (after the metadata header line and ---)
    // Body format: # TITLE\n\n**KÃªnh:** ... | ...\n\n---\n\nACTUAL_TRANSCRIPT
    const bodyParts = body.split(/\n---\n/);
    const headerPart = bodyParts[0] || '';
    const transcriptText = bodyParts.slice(1).join('\n---\n').trim();

    if (!transcriptText || transcriptText.length < 50) {
      this.log(`Transcript too short: ${filePath}`, 'warn');
      return null;
    }

    // Clean the transcript
    const { cleaned, stats } = await this.cleanTranscript(transcriptText, title, category);

    // Also clean the title if it has garbled text
    let cleanedTitle = title;
    if (this._isTitleGarbled(title)) {
      cleanedTitle = await this._cleanTitle(title, category);
    }

    // Rebuild frontmatter with cleaned title
    let cleanedFrontmatter = frontmatter;
    if (cleanedTitle !== title) {
      cleanedFrontmatter = frontmatter.replace(
        `title: "${title}"`,
        `title: "${cleanedTitle}"`
      );
    }

    // Rebuild the full file
    const cleanedHeader = cleanedTitle !== title
      ? headerPart.replace(title, cleanedTitle)
      : headerPart;
    const cleanedContent = `${cleanedFrontmatter}\n\n${cleanedHeader}\n---\n\n${cleaned}\n`;

    // Save to output directory
    const outDir = outputDir || join(TRANSCRIPTS_DIR, '..', 'transcripts-clean');
    const outPath = join(outDir, filePath);
    await mkdir(dirname(outPath), { recursive: true });
    await writeFile(outPath, cleanedContent, 'utf-8');

    return {
      file: filePath,
      titleChanged: cleanedTitle !== title,
      originalTitle: title,
      cleanedTitle,
      ...stats,
    };
  }

  /**
   * Check if title has garbled/missing diacritical marks
   */
  _isTitleGarbled(title) {
    if (!title) return false;
    // Titles that are ALL CAPS with many short words (missing diacritics) are likely garbled
    const words = title.split(/\s+/);
    const shortWords = words.filter(w => w.length <= 2 && /^[A-Z]+$/.test(w));
    // If more than 30% are 1-2 char uppercase words, likely garbled
    return shortWords.length > words.length * 0.3;
  }

  /**
   * Clean a garbled title using AI
   */
  async _cleanTitle(title, category) {
    try {
      const result = await chat({
        model: this.model,
        systemPrompt: 'Báº¡n nháº­n má»™t tiÃªu Ä‘á» video YouTube bá»‹ lá»—i dáº¥u tiáº¿ng Viá»‡t (tá»« auto-captions). HÃ£y phá»¥c há»“i tiÃªu Ä‘á» gá»‘c. CHá»ˆ tráº£ vá» tiÃªu Ä‘á» Ä‘Ã£ sá»­a, khÃ´ng giáº£i thÃ­ch.',
        userMessage: `TiÃªu Ä‘á» bá»‹ lá»—i: "${title}"\nChuyÃªn má»¥c: ${category}\n\nTiÃªu Ä‘á» Ä‘Ã£ sá»­a:`,
        temperature: 0.2,
        maxTokens: 200,
      });
      this.totalTokens.input += result.tokens.input;
      this.totalTokens.output += result.tokens.output;
      this.totalCost += estimateCost(this.model, result.tokens.input, result.tokens.output);
      return result.content.trim().replace(/^["']|["']$/g, '');
    } catch {
      return title; // Keep original on failure
    }
  }

  /**
   * Remove known sponsor/ad segments that the LLM may have missed
   */
  _removeSponsorSegments(text) {
    let cleaned = text;
    for (const pattern of SPONSOR_PATTERNS) {
      cleaned = cleaned.replace(pattern, '');
    }
    return cleaned;
  }

  /**
   * Split text into chunks with overlap
   */
  _splitIntoChunks(text) {
    if (text.length <= CHUNK_SIZE) return [text];

    const chunks = [];
    let start = 0;

    while (start < text.length) {
      let end = start + CHUNK_SIZE;
      
      // Try to break at a sentence boundary
      if (end < text.length) {
        const searchStart = Math.max(0, end - 200);
        const searchEnd = Math.min(text.length, end + 200);
        const searchZone = text.substring(searchStart, searchEnd);
        const sentenceEnd = searchZone.search(/[.!?ã€‚]\s/);
        if (sentenceEnd !== -1) {
          end = searchStart + sentenceEnd + 2;
        }
      } else {
        end = text.length;
      }

      chunks.push(text.substring(start, end));

      // Next start with overlap, but stop if remaining is too small
      const nextStart = end - CHUNK_OVERLAP;
      if (nextStart <= start || end >= text.length) break; // Prevent infinite loop
      start = nextStart;
    }

    return chunks;
  }

  /**
   * Merge cleaned chunks, removing potential overlap duplicates
   */
  _mergeChunks(chunks) {
    if (chunks.length <= 1) return chunks[0] || '';

    let result = chunks[0];
    for (let i = 1; i < chunks.length; i++) {
      const chunk = chunks[i];
      // Try to find overlap point
      const overlapSearch = result.substring(result.length - 300);
      const chunkStart = chunk.substring(0, 300);

      // Find longest common substring at the boundary
      let bestOverlap = 0;
      for (let len = 20; len < Math.min(overlapSearch.length, chunkStart.length); len++) {
        const tail = overlapSearch.substring(overlapSearch.length - len);
        if (chunkStart.startsWith(tail)) {
          bestOverlap = len;
        }
      }

      if (bestOverlap > 20) {
        // Merge with overlap removal
        result += chunk.substring(bestOverlap);
      } else {
        // No clean overlap found â€” just concat with paragraph break
        result += '\n\n' + chunk;
      }
    }

    return result;
  }
}

export default TranscriptCleanerAgent;
