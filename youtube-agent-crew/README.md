# YouTube Agent Crew ðŸš€

**AI-Powered Podcast Video Factory** â€” Feed it a YouTube URL, get a full podcast episode back.

Built by LongSang Admin. Elon Musk mode: ON.

## Architecture

```
URL Input â†’ [Harvester] â†’ [Brain Curator] â†’ [Script Writer] â†’ [Voice Producer] â†’ [Visual Director] â†’ [Video Assembler] â†’ [Publisher]
    â†•            â†•              â†•                â†•                  â†•                  â†•                   â†•               â†•
                              Message Bus (EventEmitter3)
                              Shared Memory (in-memory + Supabase)
                              Conductor (orchestrator)
```

### 7 Agents

| # | Agent | Role | Model |
|---|-------|------|-------|
| 1 | ðŸ” Harvester | YouTube content extraction | gpt-4o-mini |
| 2 | ðŸ§  Brain Curator | Knowledge analysis + Brain storage | gpt-4o-mini |
| 3 | âœï¸ Script Writer | Podcast script in YOUR voice | gpt-4o-mini |
| 4 | ðŸŽ™ï¸ Voice Producer | TTS preparation + audio generation | gpt-4o-mini |
| 5 | ðŸŽ¬ Visual Director | Visual storyboard + image prompts | gpt-4o-mini |
| 6 | ðŸŽ¥ Video Assembler | FFmpeg video assembly | gpt-4o-mini |
| 7 | ðŸ“¤ Publisher | YouTube SEO + metadata | gpt-4o-mini |

### Core Framework

- **BaseAgent** â€” Execute â†’ Think â†’ Act â†’ Report
- **Conductor** â€” Pipeline orchestrator, cost tracker
- **MessageBus** â€” Inter-agent communication
- **SharedMemory** â€” Cross-agent state management
- **LLM** â€” Provider abstraction (OpenAI, Gemini, Anthropic)

## Quick Start

```bash
# 1. Install dependencies
npm install

# 2. Configure API keys
cp .env.example .env
# Edit .env with your keys (minimum: OPENAI_API_KEY)

# 3. Run!
node src/index.js --url "https://www.youtube.com/watch?v=VIDEO_ID"
```

## Usage

```bash
# Transform a specific video into a podcast
node src/index.js --url "https://www.youtube.com/watch?v=XXX"

# Create a podcast about a topic
node src/index.js --topic "Táº¡i sao Fed in tiá»n áº£nh hÆ°á»Ÿng Ä‘áº¿n BÄS Viá»‡t Nam"

# Harvest latest from a channel
node src/index.js --channel "THUáº¬T TÃ€I Váº¬N" --latest

# Dry run (no TTS/video, just script + metadata)
node src/index.js --topic "Chu ká»³ 18 nÄƒm" --dry-run
```

## Output

Each run creates a folder in `./output/` with:
- `results.json` â€” Full pipeline results
- `script.json` â€” Structured podcast script
- `script.txt` â€” Human-readable script
- `metadata.json` â€” YouTube SEO metadata
- `audio/` â€” Generated audio chunks (if TTS configured)
- `video/` â€” Final video (if FFmpeg available)

## Cost Estimate

Using gpt-4o-mini for all agents:
- **~$0.01-0.03 per video** (mostly script writing)
- TTS cost depends on provider (Fish Speech = free self-hosted)

## Configuration

### Required
- `OPENAI_API_KEY` â€” For all agent LLM calls

### Optional
- `GOOGLE_AI_API_KEY` â€” For Gemini models (cheaper alternative)
- `FISH_SPEECH_API_URL` â€” Self-hosted TTS
- `ELEVENLABS_API_KEY` â€” Cloud TTS alternative
- `ADMIN_API_URL` â€” LongSang Admin Brain API connection
- `SUPABASE_URL` / `SUPABASE_KEY` â€” For persistent memory

## Extending

### Add a new agent
```javascript
import { BaseAgent } from './core/agent.js';

class MyAgent extends BaseAgent {
  constructor() {
    super({
      id: 'my-agent',
      name: 'ðŸ¤– My Agent',
      role: 'Does amazing things',
      systemPrompt: '...',
    });
  }
}
```

### Add a new pipeline
```javascript
export const myPipeline = {
  name: 'my-pipeline',
  stages: [
    {
      name: 'Stage 1',
      agentId: 'my-agent',
      outputKey: 'stage_1_output',
      task: (memory, input) => `Do something with ${input.data}`,
    },
  ],
};
```

## Tech Stack

- **Runtime**: Node.js 18+ (ES Modules)
- **LLM**: OpenAI GPT-4o-mini (primary), Google Gemini (fallback)
- **TTS**: Fish Speech (self-hosted) / ElevenLabs
- **Video**: FFmpeg (MVP) / Remotion (future)
- **Communication**: EventEmitter3 message bus
- **YouTube**: youtubei.js (unofficial API, no key needed)

## License

MIT â€” Ship fast, iterate faster.
